{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b41e576e-69f1-4591-8523-8a982d20769b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "### 질병: af ###\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    train_test_split\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# FEATURES = {\n",
    "#     \"af\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"PRSice2\"],\n",
    "#     \"chd\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"BG\",\"TRIG\",\"CREAT\",\"SBP\",\"HGT\",\"DBP\",\"CALC_LDL\",\"HDL\",\"DLVH\",\"CURRSMK\",\"HIP\",\"PRSice2\"],\n",
    "#     \"chf\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"CREAT\",\"BG\",\"TRIG\",\"HGT\",\"SBP\",\"DBP\",\"CALC_LDL\",\"HDL\",\"DLVH\",\"CURRSMK\",\"HIP\",\"PRSice2\"],\n",
    "#     \"dem\": [\"AGE\",\"SEX\",\"VENT_RT\", \"CREAT\", \"BG\", \"alcohol\", \"TRIG\", \"DBP\", \"HGT\", \"SBP\", \"DLVH\", \"CALC_LDL\", \"HDL\", \"CPD\", \"HIP\",\"LDpred\"],\n",
    "#     \"dia\": [\"AGE\",\"SEX\",\"TRIG\",\"VENT_RT\",\"HIP\",\"CREAT\",\"alcohol\",\"BG\",\"CALC_LDL\",\"DBP\",\"SBP\",\"DLVH\",\"HDL\",\"TC\",\"CURRSMK\",\"BMI\",\"HGT\",\"LDpred\"],\n",
    "#     \"stroke\": [\"AGE\",\"SEX\",\"CREAT\",\"TRIG\",\"BG\",\"VENT_RT\",\"alcohol\",\"DBP\",\"CALC_LDL\",\"HDL\",\"SBP\",\"DLVH\",\"CPD\",\"HIP\",\"HGT\",\"Lasso\"]\n",
    "# }\n",
    "\n",
    "# FEATURES = {\n",
    "#     \"af\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"],\n",
    "#     \"chd\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"BG\",\"TRIG\",\"CREAT\",\"SBP\",\"HGT\",\"DBP\",\"CALC_LDL\",\"HDL\",\"DLVH\",\"CURRSMK\",\"HIP\"],\n",
    "#     \"chf\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"CREAT\",\"BG\",\"TRIG\",\"HGT\",\"SBP\",\"DBP\",\"CALC_LDL\",\"HDL\",\"DLVH\",\"CURRSMK\",\"HIP\"],\n",
    "#     \"dem\": [\"AGE\",\"SEX\",\"VENT_RT\", \"CREAT\", \"BG\", \"alcohol\", \"TRIG\", \"DBP\", \"HGT\", \"SBP\", \"DLVH\", \"CALC_LDL\", \"HDL\", \"CPD\", \"HIP\"],\n",
    "#     \"dia\": [\"AGE\",\"SEX\",\"TRIG\",\"VENT_RT\",\"HIP\",\"CREAT\",\"alcohol\",\"BG\",\"CALC_LDL\",\"DBP\",\"SBP\",\"DLVH\",\"HDL\",\"TC\",\"CURRSMK\",\"BMI\",\"HGT\"],\n",
    "#     \"stroke\": [\"AGE\",\"SEX\",\"CREAT\",\"TRIG\",\"BG\",\"VENT_RT\",\"alcohol\",\"DBP\",\"CALC_LDL\",\"HDL\",\"SBP\",\"DLVH\",\"CPD\",\"HIP\",\"HGT\"]\n",
    "# }\n",
    "\n",
    "#prs\n",
    "FEATURES = {\n",
    "    \"af\": [\"AGE\",\"SEX\",\"PRSice2\"],\n",
    "    \"chd\": [\"AGE\",\"SEX\",\"PRSice2\"],\n",
    "    \"chf\": [\"AGE\",\"SEX\",\"PRSice2\"],\n",
    "    \"dem\": [\"AGE\",\"SEX\",\"LDpred\"],\n",
    "    \"dia\": [\"AGE\",\"SEX\",\"LDpred\"],\n",
    "    \"stroke\": [\"AGE\",\"SEX\",\"Lasso\"]\n",
    "}\n",
    "\n",
    "\n",
    "FILES = {\n",
    "    \"dia\":    \"/Data/taegun/prs_revision/data/df_diabet_phenotype_final.csv\",\n",
    "    \"chf\":    \"/Data/taegun/prs_revision/data/df_chf_phenotype_final.csv\",\n",
    "    \"chd\":    \"/Data/taegun/prs_revision/data/df_chd_phenotype_final.csv\",\n",
    "    \"stroke\": \"/Data/taegun/prs_revision/data/df_stroke_phenotype_final.csv\",\n",
    "    \"af\":     \"/Data/taegun/prs_revision/data/df_af_phenotype_final.csv\",\n",
    "    \"dem\":    \"/Data/taegun/prs_revision/data/df_dem_phenotype_final.csv\"\n",
    "}\n",
    "\n",
    "TARGET_NAME = {k: \"Disease_status\" for k in FILES.keys()}\n",
    "\n",
    "disease = \"af\"\n",
    "\n",
    "print(f\"\\n\\n\\n==============================\")\n",
    "print(f\"### 질병: {disease} ###\")\n",
    "print(\"==============================\")\n",
    "\n",
    "df = pd.read_csv(FILES[disease])\n",
    "features = FEATURES[disease]\n",
    "target = TARGET_NAME[disease]\n",
    "\n",
    "df_sub = df[features + [target]].dropna()\n",
    "\n",
    "X = df_sub[features]\n",
    "y = df_sub[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "673d16be-006b-4a8b-8e22-43c2e68f7c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred, y_proba):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    sensitivity = tp / (tp + fn + 1e-8)\n",
    "    specificity = tn / (tn + fp + 1e-8)\n",
    "\n",
    "    lr_plus = sensitivity / (1 - specificity + 1e-8)\n",
    "    lr_minus = (1 - sensitivity) / (specificity + 1e-8)\n",
    "    dor = lr_plus / (lr_minus + 1e-8)\n",
    "\n",
    "    return auc, sensitivity, specificity, dor, lr_plus, lr_minus\n",
    "\n",
    "def apply_sampling(X, y, method, ratio, random_state=42):\n",
    "\n",
    "    if method == \"undersample\":\n",
    "        sampler = RandomUnderSampler(\n",
    "            sampling_strategy=ratio,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        return sampler.fit_resample(X, y)\n",
    "\n",
    "    elif method == \"smote\":\n",
    "        sampler = SMOTE(\n",
    "            sampling_strategy=ratio,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        return sampler.fit_resample(X, y)\n",
    "\n",
    "    else:\n",
    "        return X.copy(), y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c98c69b-5bb2-436b-abc8-eec427f40511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_catboost_final_pipeline(\n",
    "    X,\n",
    "    y,\n",
    "    disease,\n",
    "    save_dir,\n",
    "    sampling_methods=[\"none\", \"undersample\", \"smote\", \"class_weight\"],\n",
    "    sampling_ratios=[0.6, 0.8, 1.0],\n",
    "):\n",
    "    \"\"\"\n",
    "    논문용 최종 파이프라인\n",
    "    1) Train / Validation split\n",
    "    2) Train set에서 GridSearchCV\n",
    "    3) 최적 모델로 Train 전체 재학습\n",
    "    4) Validation set 단 1회 평가\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # ======================================================\n",
    "    # 1. Train / Validation split\n",
    "    # ======================================================\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        stratify=y,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # ======================================================\n",
    "    # 2. Scaling\n",
    "    # ======================================================\n",
    "    cols_to_scale = [c for c in X.columns if c not in [\"AGE\", \"SEX\", \"CURRSMK\"]]\n",
    "\n",
    "    scaler = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"scale\", StandardScaler(), cols_to_scale)\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    # ======================================================\n",
    "    # 3. CatBoost base model\n",
    "    # ======================================================\n",
    "    cat = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"AUC\",\n",
    "        random_seed=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    # ======================================================\n",
    "    # 4. Hyperparameter grid\n",
    "    # ======================================================\n",
    "    param_grid = {\n",
    "        \"model__n_estimators\": [100, 300, 500],\n",
    "        \"model__max_depth\": [5, 10],\n",
    "        \"model__learning_rate\": [0.1, 0.3],\n",
    "        \"model__l2_leaf_reg\": [1, 3],\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    grid_logs = []\n",
    "    final_logs = []\n",
    "\n",
    "    # ======================================================\n",
    "    # 5. Sampling loop + GridSearch\n",
    "    # ======================================================\n",
    "    for sm in sampling_methods:\n",
    "\n",
    "        ratios = sampling_ratios if sm in [\"undersample\", \"smote\"] else [None]\n",
    "\n",
    "        for ratio in ratios:\n",
    "\n",
    "            print(f\"\\n>>> [{disease}] Sampling={sm}, Ratio={ratio}\")\n",
    "\n",
    "            # --------------------------\n",
    "            # Sampling (Train only)\n",
    "            # --------------------------\n",
    "            X_res, y_res = apply_sampling(X_train, y_train, sm, ratio)\n",
    "\n",
    "            # --------------------------\n",
    "            # Pipeline\n",
    "            # --------------------------\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", scaler),\n",
    "                (\"model\", cat)\n",
    "            ])\n",
    "\n",
    "            if sm == \"class_weight\":\n",
    "                pipe.set_params(model__auto_class_weights=\"Balanced\")\n",
    "\n",
    "            # --------------------------\n",
    "            # GridSearchCV\n",
    "            # --------------------------\n",
    "            grid = GridSearchCV(\n",
    "                estimator=pipe,\n",
    "                param_grid=param_grid,\n",
    "                scoring=\"roc_auc\",\n",
    "                cv=cv,\n",
    "                n_jobs=1,\n",
    "                verbose=1,\n",
    "                return_train_score=True\n",
    "            )\n",
    "\n",
    "            grid.fit(X_res, y_res)\n",
    "\n",
    "            # --------------------------\n",
    "            # Grid 결과 저장\n",
    "            # --------------------------\n",
    "            df_grid = pd.DataFrame(grid.cv_results_)\n",
    "            df_grid[\"sampling_method\"] = sm\n",
    "            df_grid[\"sampling_ratio\"] = ratio\n",
    "            grid_logs.append(df_grid)\n",
    "\n",
    "            # ==================================================\n",
    "            # 6. 최적 모델 → Validation 평가\n",
    "            # ==================================================\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "            y_val_pred = (y_val_proba > 0.5).astype(int)\n",
    "\n",
    "            auc, sen, spe, dor, lr_p, lr_m = calc_metrics(\n",
    "                y_val, y_val_pred, y_val_proba\n",
    "            )\n",
    "\n",
    "            final_logs.append({\n",
    "                \"disease\": disease,\n",
    "                \"sampling_method\": sm,\n",
    "                \"sampling_ratio\": ratio,\n",
    "                \"AUC\": auc,\n",
    "                \"sensitivity\": sen,\n",
    "                \"specificity\": spe,\n",
    "                \"DOR\": dor,\n",
    "                \"LR+\": lr_p,\n",
    "                \"LR-\": lr_m,\n",
    "                **grid.best_params_\n",
    "            })\n",
    "\n",
    "    # ======================================================\n",
    "    # 7. 결과 정리 & 저장\n",
    "    # ======================================================\n",
    "    df_grid_all = pd.concat(grid_logs, ignore_index=True)\n",
    "    df_final = pd.DataFrame(final_logs)\n",
    "\n",
    "    best_row = df_final.loc[df_final[\"AUC\"].idxmax()]\n",
    "\n",
    "    df_grid_all.to_csv(\n",
    "        f\"{save_dir}/{disease}_catboost_gridsearch_results.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    df_final.to_csv(\n",
    "        f\"{save_dir}/{disease}_catboost_validation_results.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    pd.DataFrame([best_row]).to_csv(\n",
    "        f\"{save_dir}/{disease}_catboost_best_model.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"\\n>>> [{disease}] 결과 저장 완료\")\n",
    "\n",
    "    return {\n",
    "        \"grid_results\": df_grid_all,\n",
    "        \"validation_results\": df_final,\n",
    "        \"best_model\": best_row\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20870313-7640-49ae-a17a-85fc2baa5e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================\n",
      "### GridSearch: DIA ###\n",
      "===================================\n",
      "\n",
      ">>> [dia] Sampling=none, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dia] Sampling=undersample, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dia] Sampling=undersample, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dia] Sampling=undersample, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dia] Sampling=smote, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dia] Sampling=smote, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dia] Sampling=smote, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dia] Sampling=class_weight, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124309/1777047649.py:144: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_grid_all = pd.concat(grid_logs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [dia] 결과 저장 완료\n",
      "\n",
      "===================================\n",
      "### GridSearch: CHF ###\n",
      "===================================\n",
      "\n",
      ">>> [chf] Sampling=none, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chf] Sampling=undersample, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chf] Sampling=undersample, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chf] Sampling=undersample, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chf] Sampling=smote, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chf] Sampling=smote, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chf] Sampling=smote, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chf] Sampling=class_weight, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124309/1777047649.py:144: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_grid_all = pd.concat(grid_logs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [chf] 결과 저장 완료\n",
      "\n",
      "===================================\n",
      "### GridSearch: CHD ###\n",
      "===================================\n",
      "\n",
      ">>> [chd] Sampling=none, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chd] Sampling=undersample, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chd] Sampling=undersample, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chd] Sampling=undersample, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chd] Sampling=smote, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chd] Sampling=smote, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chd] Sampling=smote, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [chd] Sampling=class_weight, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124309/1777047649.py:144: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_grid_all = pd.concat(grid_logs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [chd] 결과 저장 완료\n",
      "\n",
      "===================================\n",
      "### GridSearch: STROKE ###\n",
      "===================================\n",
      "\n",
      ">>> [stroke] Sampling=none, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [stroke] Sampling=undersample, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [stroke] Sampling=undersample, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [stroke] Sampling=undersample, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [stroke] Sampling=smote, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [stroke] Sampling=smote, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [stroke] Sampling=smote, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [stroke] Sampling=class_weight, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124309/1777047649.py:144: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_grid_all = pd.concat(grid_logs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [stroke] 결과 저장 완료\n",
      "\n",
      "===================================\n",
      "### GridSearch: AF ###\n",
      "===================================\n",
      "\n",
      ">>> [af] Sampling=none, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [af] Sampling=undersample, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [af] Sampling=undersample, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [af] Sampling=undersample, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [af] Sampling=smote, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [af] Sampling=smote, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [af] Sampling=smote, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [af] Sampling=class_weight, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124309/1777047649.py:144: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_grid_all = pd.concat(grid_logs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [af] 결과 저장 완료\n",
      "\n",
      "===================================\n",
      "### GridSearch: DEM ###\n",
      "===================================\n",
      "\n",
      ">>> [dem] Sampling=none, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dem] Sampling=undersample, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dem] Sampling=undersample, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dem] Sampling=undersample, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dem] Sampling=smote, Ratio=0.6\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dem] Sampling=smote, Ratio=0.8\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dem] Sampling=smote, Ratio=1.0\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dem] Sampling=class_weight, Ratio=None\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      ">>> [dem] 결과 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124309/1777047649.py:144: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_grid_all = pd.concat(grid_logs, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    disease_list = [\"dia\", \"chf\", \"chd\", \"stroke\", \"af\", \"dem\"]\n",
    "\n",
    "    for disease in disease_list:\n",
    "\n",
    "        print(\"\\n===================================\")\n",
    "        print(f\"### GridSearch: {disease.upper()} ###\")\n",
    "        print(\"===================================\")\n",
    "\n",
    "        df = pd.read_csv(FILES[disease])\n",
    "        features = FEATURES[disease]\n",
    "        target = TARGET_NAME[disease]\n",
    "\n",
    "        df_sub = df[features + [target]].dropna()\n",
    "        X = df_sub[features]\n",
    "        y = df_sub[target]\n",
    "\n",
    "        SAVE_DIR = f\"/Data/taegun/prs_revision/1215_analysis/prs_model/catboost_param/{disease}\"\n",
    "        os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "        \n",
    "        res = run_catboost_final_pipeline(X, y, disease, SAVE_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prsml)",
   "language": "python",
   "name": "prsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
