{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b31646-a846-494f-b2a1-7d035331de0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "### ì§ˆë³‘: af ###\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    train_test_split\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# FEATURES = {\n",
    "#     \"af\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"PRSice2\"],\n",
    "#     \"chd\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"LDpred\"],\n",
    "#     \"chf\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"PRSice2\"],\n",
    "#     \"dem\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"LDpred\"],\n",
    "#     \"dia\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"LDpred\"],\n",
    "#     \"stroke\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"Lasso\"]\n",
    "# }\n",
    "\n",
    "# FEATURES = {\n",
    "#     \"af\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"],\n",
    "#     \"chd\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"],\n",
    "#     \"chf\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"],\n",
    "#     \"dem\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"],\n",
    "#     \"dia\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"],\n",
    "#     \"stroke\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"]\n",
    "# }\n",
    "\n",
    "#prs\n",
    "FEATURES = {\n",
    "    \"af\": [\"AGE\",\"SEX\",\"PRSice2\"],\n",
    "    \"chd\": [\"AGE\",\"SEX\",\"LDpred\"],\n",
    "    \"chf\": [\"AGE\",\"SEX\",\"PRSice2\"],\n",
    "    \"dem\": [\"AGE\",\"SEX\",\"LDpred\"],\n",
    "    \"dia\": [\"AGE\",\"SEX\",\"LDpred\"],\n",
    "    \"stroke\": [\"AGE\",\"SEX\",\"Lasso\"]\n",
    "}\n",
    "\n",
    "# FILES = {\n",
    "#     \"dia\":    \"/Data/taegun/prs_revision/data/df_diabet_phenotype_final.csv\",\n",
    "#     \"chf\":    \"/Data/taegun/prs_revision/data/df_chf_phenotype_final.csv\",\n",
    "#     \"chd\":    \"/Data/taegun/prs_revision/data/df_chd_phenotype_final.csv\",\n",
    "#     \"stroke\": \"/Data/taegun/prs_revision/data/df_stroke_phenotype_final.csv\",\n",
    "#     \"af\":     \"/Data/taegun/prs_revision/data/df_af_phenotype_final.csv\",\n",
    "#     \"dem\":    \"/Data/taegun/prs_revision/data/df_dem_phenotype_final.csv\"\n",
    "# }\n",
    "FILES = {\n",
    "    \"dia\":    \"/Data/taegun/prs_revision/data/df_diabet_match_pcr_final2.csv\",\n",
    "    \"chf\":    \"/Data/taegun/prs_revision/data/df_chf_match_pcr_final2.csv\",\n",
    "    \"chd\":    \"/Data/taegun/prs_revision/data/df_chd_match_pcr_final2.csv\",\n",
    "    \"stroke\": \"/Data/taegun/prs_revision/data/df_stroke_match_pcr_final2.csv\",\n",
    "    \"af\":     \"/Data/taegun/prs_revision/data/df_af_match_pcr_final2.csv\",\n",
    "    \"dem\":    \"/Data/taegun/prs_revision/data/df_dem_match_pcr_final2.csv\"\n",
    "}\n",
    "TARGET_NAME = {k: \"Disease_status\" for k in FILES.keys()}\n",
    "\n",
    "disease = \"af\"\n",
    "\n",
    "print(f\"\\n\\n\\n==============================\")\n",
    "print(f\"### ì§ˆë³‘: {disease} ###\")\n",
    "print(\"==============================\")\n",
    "\n",
    "df = pd.read_csv(FILES[disease])\n",
    "features = FEATURES[disease]\n",
    "target = TARGET_NAME[disease]\n",
    "\n",
    "df_sub = df[features + [target]].dropna()\n",
    "\n",
    "X = df_sub[features]\n",
    "y = df_sub[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b6cf7a1-2ee1-44f5-b228-ecfb9dee9b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred, y_proba):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    sensitivity = tp / (tp + fn + 1e-8)\n",
    "    specificity = tn / (tn + fp + 1e-8)\n",
    "\n",
    "    lr_plus = sensitivity / (1 - specificity + 1e-8)\n",
    "    lr_minus = (1 - sensitivity) / (specificity + 1e-8)\n",
    "    dor = lr_plus / (lr_minus + 1e-8)\n",
    "\n",
    "    return auc, sensitivity, specificity, dor, lr_plus, lr_minus\n",
    "\n",
    "def apply_sampling(X, y, method, ratio, random_state=42):\n",
    "\n",
    "    if method == \"undersample\":\n",
    "        sampler = RandomUnderSampler(\n",
    "            sampling_strategy=ratio,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        return sampler.fit_resample(X, y)\n",
    "\n",
    "    elif method == \"smote\":\n",
    "        sampler = SMOTE(\n",
    "            sampling_strategy=ratio,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        return sampler.fit_resample(X, y)\n",
    "\n",
    "    else:\n",
    "        return X.copy(), y.copy()\n",
    "\n",
    "def xgb_auc_scorer(estimator, X, y):\n",
    "    proba = estimator.predict_proba(X)[:, 1]\n",
    "    return roc_auc_score(y, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd6f5932-0c61-4107-975b-1d194684bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb_final_pipeline(\n",
    "    X,\n",
    "    y,\n",
    "    disease,\n",
    "    save_dir,\n",
    "    sampling_methods=[\"none\", \"undersample\", \"smote\", \"class_weight\"],\n",
    "    sampling_ratios=[0.6, 0.8, 1.0],\n",
    "):\n",
    "    \"\"\"\n",
    "    ë…¼ë¬¸ìš© ìµœì¢… íŒŒì´í”„ë¼ì¸\n",
    "    1) Train / Validation split\n",
    "    2) Train setì—ì„œ GridSearchCV\n",
    "    3) ìµœì  ëª¨ë¸ë¡œ Train ì „ì²´ ìž¬í•™ìŠµ\n",
    "    4) Validation set ë‹¨ 1íšŒ í‰ê°€\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # ======================================================\n",
    "    # 1. Train / Validation split\n",
    "    # ======================================================\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        stratify=y,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # ======================================================\n",
    "    # 2. Scaling\n",
    "    # ======================================================\n",
    "    cols_to_scale = [c for c in X.columns if c not in [\"AGE\", \"SEX\", \"DLVH\"]]\n",
    "\n",
    "    scaler = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"scale\", StandardScaler(), cols_to_scale)\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    # ======================================================\n",
    "    # 3. XGBoost base model\n",
    "    # ======================================================\n",
    "    xgb = XGBClassifier(\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cpu\",\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # ======================================================\n",
    "    # 4. Hyperparameter grid\n",
    "    # ======================================================\n",
    "    param_grid = {\n",
    "        \"model__n_estimators\": [100, 300, 500],\n",
    "        \"model__max_depth\": [3, 5, 10],\n",
    "        \"model__learning_rate\": [0.1, 0.3],\n",
    "        \"model__subsample\": [0.6, 1.0],\n",
    "        \"model__colsample_bytree\": [0.7, 1.0],\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    grid_logs = []\n",
    "    final_logs = []\n",
    "\n",
    "    # ======================================================\n",
    "    # 5. Sampling loop + GridSearch\n",
    "    # ======================================================\n",
    "    for sm in sampling_methods:\n",
    "\n",
    "        ratios = sampling_ratios if sm in [\"undersample\", \"smote\"] else [None]\n",
    "\n",
    "        for ratio in ratios:\n",
    "\n",
    "            print(f\"\\n>>> [{disease}] Sampling={sm}, Ratio={ratio}\")\n",
    "\n",
    "            # --------------------------\n",
    "            # Sampling (Train only)\n",
    "            # --------------------------\n",
    "            X_res, y_res = apply_sampling(X_train, y_train, sm, ratio)\n",
    "\n",
    "            # --------------------------\n",
    "            # Pipeline\n",
    "            # --------------------------\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", scaler),\n",
    "                (\"model\", xgb)\n",
    "            ])\n",
    "\n",
    "            if sm == \"class_weight\":\n",
    "                scale_pos_weight = (len(y_res) - sum(y_res)) / sum(y_res)\n",
    "                pipe.set_params(model__scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "            # --------------------------\n",
    "            # GridSearchCV\n",
    "            # --------------------------\n",
    "            for i, (tr, te) in enumerate(cv.split(X_res, y_res)):\n",
    "                uniq, cnt = np.unique(y_res.iloc[te], return_counts=True)\n",
    "                print(i, dict(zip(uniq, cnt)))\n",
    "            grid = GridSearchCV(\n",
    "                estimator=pipe,\n",
    "                param_grid=param_grid,\n",
    "                scoring=xgb_auc_scorer,\n",
    "                cv=cv,\n",
    "                n_jobs=-1,\n",
    "                verbose=1,\n",
    "                return_train_score=True,\n",
    "                error_score=\"raise\"   # ðŸ”¥ ì´ê±°\n",
    "            )\n",
    "            grid.fit(X_res, y_res)\n",
    "\n",
    "            # --------------------------\n",
    "            # Grid ê²°ê³¼ ì €ìž¥\n",
    "            # --------------------------\n",
    "            df_grid = pd.DataFrame(grid.cv_results_)\n",
    "            df_grid[\"sampling_method\"] = sm\n",
    "            df_grid[\"sampling_ratio\"] = ratio\n",
    "            grid_logs.append(df_grid)\n",
    "\n",
    "            # ==================================================\n",
    "            # 6. ìµœì  ëª¨ë¸ â†’ Validation í‰ê°€\n",
    "            # ==================================================\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "            y_val_pred = (y_val_proba > 0.5).astype(int)\n",
    "\n",
    "            auc, sen, spe, dor, lr_p, lr_m = calc_metrics(\n",
    "                y_val, y_val_pred, y_val_proba\n",
    "            )\n",
    "\n",
    "            final_logs.append({\n",
    "                \"disease\": disease,\n",
    "                \"sampling_method\": sm,\n",
    "                \"sampling_ratio\": ratio,\n",
    "                \"AUC\": auc,\n",
    "                \"sensitivity\": sen,\n",
    "                \"specificity\": spe,\n",
    "                \"DOR\": dor,\n",
    "                \"LR+\": lr_p,\n",
    "                \"LR-\": lr_m,\n",
    "                **grid.best_params_\n",
    "            })\n",
    "\n",
    "    # ======================================================\n",
    "    # 7. ê²°ê³¼ ì •ë¦¬ & ì €ìž¥\n",
    "    # ======================================================\n",
    "    df_grid_all = pd.concat(grid_logs, ignore_index=True)\n",
    "    df_final = pd.DataFrame(final_logs)\n",
    "\n",
    "    best_row = df_final.loc[df_final[\"AUC\"].idxmax()]\n",
    "\n",
    "    df_grid_all.to_csv(\n",
    "        f\"{save_dir}/{disease}_xgb_gridsearch_results.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    df_final.to_csv(\n",
    "        f\"{save_dir}/{disease}_xgb_validation_results.csv\",\n",
    "        index=False\n",
    "    )\n",
    "    pd.DataFrame([best_row]).to_csv(\n",
    "        f\"{save_dir}/{disease}_xgb_best_model.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"\\n>>> [{disease}] ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\")\n",
    "\n",
    "    return {\n",
    "        \"grid_results\": df_grid_all,\n",
    "        \"validation_results\": df_final,\n",
    "        \"best_model\": best_row\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2384b6c2-7dad-4a97-a1c6-e7bda49f15f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================\n",
      "### GridSearch: CHF ###\n",
      "===================================\n",
      "\n",
      ">>> [chf] Sampling=none, Ratio=None\n",
      "0 {np.int64(0): np.int64(1052), np.int64(1): np.int64(81)}\n",
      "1 {np.int64(0): np.int64(1052), np.int64(1): np.int64(81)}\n",
      "2 {np.int64(0): np.int64(1052), np.int64(1): np.int64(81)}\n",
      "3 {np.int64(0): np.int64(1052), np.int64(1): np.int64(81)}\n",
      "4 {np.int64(0): np.int64(1051), np.int64(1): np.int64(82)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chf] Sampling=undersample, Ratio=0.6\n",
      "0 {np.int64(0): np.int64(136), np.int64(1): np.int64(81)}\n",
      "1 {np.int64(0): np.int64(135), np.int64(1): np.int64(82)}\n",
      "2 {np.int64(0): np.int64(135), np.int64(1): np.int64(81)}\n",
      "3 {np.int64(0): np.int64(135), np.int64(1): np.int64(81)}\n",
      "4 {np.int64(0): np.int64(135), np.int64(1): np.int64(81)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chf] Sampling=undersample, Ratio=0.8\n",
      "0 {np.int64(0): np.int64(102), np.int64(1): np.int64(81)}\n",
      "1 {np.int64(0): np.int64(102), np.int64(1): np.int64(81)}\n",
      "2 {np.int64(0): np.int64(101), np.int64(1): np.int64(82)}\n",
      "3 {np.int64(0): np.int64(101), np.int64(1): np.int64(81)}\n",
      "4 {np.int64(0): np.int64(101), np.int64(1): np.int64(81)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chf] Sampling=undersample, Ratio=1.0\n",
      "0 {np.int64(0): np.int64(82), np.int64(1): np.int64(81)}\n",
      "1 {np.int64(0): np.int64(81), np.int64(1): np.int64(82)}\n",
      "2 {np.int64(0): np.int64(81), np.int64(1): np.int64(81)}\n",
      "3 {np.int64(0): np.int64(81), np.int64(1): np.int64(81)}\n",
      "4 {np.int64(0): np.int64(81), np.int64(1): np.int64(81)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chf] Sampling=smote, Ratio=0.6\n",
      "0 {np.int64(0): np.int64(1052), np.int64(1): np.int64(631)}\n",
      "1 {np.int64(0): np.int64(1052), np.int64(1): np.int64(631)}\n",
      "2 {np.int64(0): np.int64(1052), np.int64(1): np.int64(631)}\n",
      "3 {np.int64(0): np.int64(1052), np.int64(1): np.int64(631)}\n",
      "4 {np.int64(0): np.int64(1051), np.int64(1): np.int64(631)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chf] Sampling=smote, Ratio=0.8\n",
      "0 {np.int64(0): np.int64(1052), np.int64(1): np.int64(842)}\n",
      "1 {np.int64(0): np.int64(1052), np.int64(1): np.int64(841)}\n",
      "2 {np.int64(0): np.int64(1052), np.int64(1): np.int64(841)}\n",
      "3 {np.int64(0): np.int64(1052), np.int64(1): np.int64(841)}\n",
      "4 {np.int64(0): np.int64(1051), np.int64(1): np.int64(842)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chf] Sampling=smote, Ratio=1.0\n",
      "0 {np.int64(0): np.int64(1052), np.int64(1): np.int64(1052)}\n",
      "1 {np.int64(0): np.int64(1052), np.int64(1): np.int64(1052)}\n",
      "2 {np.int64(0): np.int64(1052), np.int64(1): np.int64(1052)}\n",
      "3 {np.int64(0): np.int64(1052), np.int64(1): np.int64(1051)}\n",
      "4 {np.int64(0): np.int64(1051), np.int64(1): np.int64(1052)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chf] Sampling=class_weight, Ratio=None\n",
      "0 {np.int64(0): np.int64(1052), np.int64(1): np.int64(81)}\n",
      "1 {np.int64(0): np.int64(1052), np.int64(1): np.int64(81)}\n",
      "2 {np.int64(0): np.int64(1052), np.int64(1): np.int64(81)}\n",
      "3 {np.int64(0): np.int64(1052), np.int64(1): np.int64(81)}\n",
      "4 {np.int64(0): np.int64(1051), np.int64(1): np.int64(82)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18470/2641768386.py:150: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_grid_all = pd.concat(grid_logs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [chf] ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\n",
      "\n",
      "===================================\n",
      "### GridSearch: CHD ###\n",
      "===================================\n",
      "\n",
      ">>> [chd] Sampling=none, Ratio=None\n",
      "0 {np.int64(0): np.int64(991), np.int64(1): np.int64(142)}\n",
      "1 {np.int64(0): np.int64(991), np.int64(1): np.int64(142)}\n",
      "2 {np.int64(0): np.int64(991), np.int64(1): np.int64(142)}\n",
      "3 {np.int64(0): np.int64(991), np.int64(1): np.int64(142)}\n",
      "4 {np.int64(0): np.int64(990), np.int64(1): np.int64(143)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chd] Sampling=undersample, Ratio=0.6\n",
      "0 {np.int64(0): np.int64(237), np.int64(1): np.int64(143)}\n",
      "1 {np.int64(0): np.int64(237), np.int64(1): np.int64(142)}\n",
      "2 {np.int64(0): np.int64(237), np.int64(1): np.int64(142)}\n",
      "3 {np.int64(0): np.int64(237), np.int64(1): np.int64(142)}\n",
      "4 {np.int64(0): np.int64(237), np.int64(1): np.int64(142)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chd] Sampling=undersample, Ratio=0.8\n",
      "0 {np.int64(0): np.int64(178), np.int64(1): np.int64(142)}\n",
      "1 {np.int64(0): np.int64(178), np.int64(1): np.int64(142)}\n",
      "2 {np.int64(0): np.int64(178), np.int64(1): np.int64(142)}\n",
      "3 {np.int64(0): np.int64(177), np.int64(1): np.int64(143)}\n",
      "4 {np.int64(0): np.int64(177), np.int64(1): np.int64(142)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chd] Sampling=undersample, Ratio=1.0\n",
      "0 {np.int64(0): np.int64(143), np.int64(1): np.int64(142)}\n",
      "1 {np.int64(0): np.int64(142), np.int64(1): np.int64(143)}\n",
      "2 {np.int64(0): np.int64(142), np.int64(1): np.int64(142)}\n",
      "3 {np.int64(0): np.int64(142), np.int64(1): np.int64(142)}\n",
      "4 {np.int64(0): np.int64(142), np.int64(1): np.int64(142)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chd] Sampling=smote, Ratio=0.6\n",
      "0 {np.int64(0): np.int64(991), np.int64(1): np.int64(595)}\n",
      "1 {np.int64(0): np.int64(991), np.int64(1): np.int64(594)}\n",
      "2 {np.int64(0): np.int64(991), np.int64(1): np.int64(594)}\n",
      "3 {np.int64(0): np.int64(991), np.int64(1): np.int64(594)}\n",
      "4 {np.int64(0): np.int64(990), np.int64(1): np.int64(595)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chd] Sampling=smote, Ratio=0.8\n",
      "0 {np.int64(0): np.int64(991), np.int64(1): np.int64(793)}\n",
      "1 {np.int64(0): np.int64(991), np.int64(1): np.int64(793)}\n",
      "2 {np.int64(0): np.int64(991), np.int64(1): np.int64(792)}\n",
      "3 {np.int64(0): np.int64(991), np.int64(1): np.int64(792)}\n",
      "4 {np.int64(0): np.int64(990), np.int64(1): np.int64(793)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chd] Sampling=smote, Ratio=1.0\n",
      "0 {np.int64(0): np.int64(991), np.int64(1): np.int64(991)}\n",
      "1 {np.int64(0): np.int64(991), np.int64(1): np.int64(991)}\n",
      "2 {np.int64(0): np.int64(991), np.int64(1): np.int64(991)}\n",
      "3 {np.int64(0): np.int64(991), np.int64(1): np.int64(990)}\n",
      "4 {np.int64(0): np.int64(990), np.int64(1): np.int64(991)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chd] Sampling=class_weight, Ratio=None\n",
      "0 {np.int64(0): np.int64(991), np.int64(1): np.int64(142)}\n",
      "1 {np.int64(0): np.int64(991), np.int64(1): np.int64(142)}\n",
      "2 {np.int64(0): np.int64(991), np.int64(1): np.int64(142)}\n",
      "3 {np.int64(0): np.int64(991), np.int64(1): np.int64(142)}\n",
      "4 {np.int64(0): np.int64(990), np.int64(1): np.int64(143)}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      ">>> [chd] ê²°ê³¼ ì €ìž¥ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18470/2641768386.py:150: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_grid_all = pd.concat(grid_logs, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "#    disease_list = [\"dia\", \"chf\", \"chd\", \"stroke\", \"af\", \"dem\"]\n",
    "    disease_list = [\"chf\", \"chd\"]\n",
    "\n",
    "    for disease in disease_list:\n",
    "\n",
    "        print(\"\\n===================================\")\n",
    "        print(f\"### GridSearch: {disease.upper()} ###\")\n",
    "        print(\"===================================\")\n",
    "\n",
    "        df = pd.read_csv(FILES[disease])\n",
    "        features = FEATURES[disease]\n",
    "        target = TARGET_NAME[disease]\n",
    "\n",
    "        df_sub = df[features + [target]].dropna()\n",
    "        X = df_sub[features]\n",
    "        y = df_sub[target]\n",
    "        \n",
    "        SAVE_DIR = f\"/Data/taegun/prs_revision/0115_analysis/prs_model/xgb_param/{disease}\"\n",
    "        os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "        \n",
    "        res = run_xgb_final_pipeline(X, y, disease, SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ade89d-dce7-442d-ab3c-9656c8454dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PRSML)",
   "language": "python",
   "name": "prsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
