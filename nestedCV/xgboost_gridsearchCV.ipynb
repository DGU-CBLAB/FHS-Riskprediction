{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53cc14d0-7a17-41af-8e34-2499ad874acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "==============================\n",
      "### 질병: af ###\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# FEATURES = {\n",
    "#     \"af\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"PRSice2\"],\n",
    "#     \"chd\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"LDpred\"],\n",
    "#     \"chf\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"PRSice2\"],\n",
    "#     \"dem\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"LDpred\"],\n",
    "#     \"dia\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"LDpred\"],\n",
    "#     \"stroke\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\",\"Lasso\"]\n",
    "# }\n",
    "\n",
    "# FEATURES = {\n",
    "#     \"af\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"],\n",
    "#     \"chd\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"],\n",
    "#     \"chf\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"],\n",
    "#     \"dem\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"],\n",
    "#     \"dia\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"],\n",
    "#     \"stroke\": [\"AGE\",\"SEX\",\"VENT_RT\",\"alcohol\",\"TRIG\",\"BG\",\"CREAT\",\"SBP\",\"DBP\",\"HGT\",\"DLVH\",\"CALC_LDL\",\"HDL\",\"CPD\",\"HIP\"]\n",
    "# }\n",
    "\n",
    "\n",
    "#prs\n",
    "FEATURES = {\n",
    "    \"af\": [\"AGE\",\"SEX\",\"PRSice2\"],\n",
    "    \"chd\": [\"AGE\",\"SEX\",\"LDpred\"],\n",
    "    \"chf\": [\"AGE\",\"SEX\",\"PRSice2\"],\n",
    "    \"dem\": [\"AGE\",\"SEX\",\"LDpred\"],\n",
    "    \"dia\": [\"AGE\",\"SEX\",\"LDpred\"],\n",
    "    \"stroke\": [\"AGE\",\"SEX\",\"Lasso\"]\n",
    "}\n",
    "\n",
    "\n",
    "# FILES = {\n",
    "#     \"dia\":    \"/Data/taegun/prs_revision/data/df_diabet_phenotype_final.csv\",\n",
    "#     \"chf\":    \"/Data/taegun/prs_revision/data/df_chf_phenotype_final.csv\",\n",
    "#     \"chd\":    \"/Data/taegun/prs_revision/data/df_chd_phenotype_final.csv\",\n",
    "#     \"stroke\": \"/Data/taegun/prs_revision/data/df_stroke_phenotype_final.csv\",\n",
    "#     \"af\":     \"/Data/taegun/prs_revision/data/df_af_phenotype_final.csv\",\n",
    "#     \"dem\":    \"/Data/taegun/prs_revision/data/df_dem_phenotype_final.csv\"\n",
    "# }\n",
    "\n",
    "FILES = {\n",
    "    \"dia\":    \"/Data/taegun/prs_revision/data/df_diabet_match_pcr_final2.csv\",\n",
    "    \"chf\":    \"/Data/taegun/prs_revision/data/df_chf_match_pcr_final2.csv\",\n",
    "    \"chd\":    \"/Data/taegun/prs_revision/data/df_chd_match_pcr_final2.csv\",\n",
    "    \"stroke\": \"/Data/taegun/prs_revision/data/df_stroke_match_pcr_final2.csv\",\n",
    "    \"af\":     \"/Data/taegun/prs_revision/data/df_af_match_pcr_final2.csv\",\n",
    "    \"dem\":    \"/Data/taegun/prs_revision/data/df_dem_match_pcr_final2.csv\"\n",
    "}\n",
    "\n",
    "\n",
    "TARGET_NAME = {k: \"Disease_status\" for k in FILES.keys()}\n",
    "\n",
    "disease = \"af\"\n",
    "\n",
    "print(f\"\\n\\n\\n==============================\")\n",
    "print(f\"### 질병: {disease} ###\")\n",
    "print(\"==============================\")\n",
    "\n",
    "df = pd.read_csv(FILES[disease])\n",
    "features = FEATURES[disease]\n",
    "target = TARGET_NAME[disease]\n",
    "\n",
    "df_sub = df[features + [target]].dropna()\n",
    "\n",
    "X = df_sub[features]\n",
    "y = df_sub[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad8f69c-2054-475c-ad67-76b562fb176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 평가 지표 계산 함수\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 평가 지표 계산 함수\n",
    "# --------------------------\n",
    "def get_metrics(y_true, y_pred, y_proba):\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    auprc = average_precision_score(y_true, y_proba)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    sensitivity = tp / (tp + fn + 1e-8)\n",
    "    specificity = tn / (tn + fp + 1e-8)\n",
    "\n",
    "    lr_plus = sensitivity / (1 - specificity + 1e-8)\n",
    "    lr_minus = (1 - sensitivity) / (specificity + 1e-8)\n",
    "    dor = lr_plus / (lr_minus + 1e-8)\n",
    "\n",
    "    return auc, auprc, sensitivity, specificity, dor, lr_plus, lr_minus\n",
    "    \n",
    "\n",
    "# ============================================================\n",
    "# XGBoost Nested CV (CPU 버전)\n",
    "# CatBoost 코드 구조와 동일하게 재작성\n",
    "# ============================================================\n",
    "def run_xgb_nested_cv_cpu(\n",
    "    X,\n",
    "    y,\n",
    "    sampling_methods=[\"none\", \"undersample\", \"smote\", \"class_weight\"],\n",
    "    sampling_ratios=[0.6, 0.8, 1.0],\n",
    "):\n",
    "\n",
    "    # --------------------------\n",
    "    # Hyperparameter Grid\n",
    "    # --------------------------\n",
    "    xgb_params = {\n",
    "        \"n_estimators\": [100, 300, 500],\n",
    "        \"max_depth\": [3, 5, 10],\n",
    "        \"learning_rate\": [0.1, 0.3],\n",
    "        \"subsample\": [0.6, 1.0],\n",
    "        \"colsample_bytree\": [0.7, 1.0]\n",
    "    }\n",
    "\n",
    "    outer = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "    all_inner_logs = []\n",
    "    all_best_models = []\n",
    "    all_outer_tests = []\n",
    "\n",
    "    # ============================================================\n",
    "    # OUTER LOOP\n",
    "    # ============================================================\n",
    "    for outer_fold, (train_idx, test_idx) in enumerate(outer.split(X, y), 1):\n",
    "\n",
    "        X_train_outer = X.iloc[train_idx].copy()\n",
    "        X_test_outer = X.iloc[test_idx].copy()\n",
    "        y_train_outer = y.iloc[train_idx]\n",
    "        y_test_outer = y.iloc[test_idx]\n",
    "\n",
    "        # Scaling\n",
    "        scaler = StandardScaler()\n",
    "        cols_to_scale = [c for c in X.columns if c not in [\"AGE\", \"SEX\", \"DLVH\"]]\n",
    "        X_train_outer[cols_to_scale] = scaler.fit_transform(X_train_outer[cols_to_scale])\n",
    "        X_test_outer[cols_to_scale] = scaler.transform(X_test_outer[cols_to_scale])\n",
    "\n",
    "        inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "        inner_log = []\n",
    "        avg_auc_list = []\n",
    "\n",
    "        # ============================================================\n",
    "        # INNER LOOP (모든 샘플링 × 하이퍼파라미터 조합 탐색)\n",
    "        # ============================================================\n",
    "        for sampling_method in sampling_methods:\n",
    "\n",
    "            ratios = sampling_ratios if sampling_method in [\"undersample\", \"smote\"] else [None]\n",
    "\n",
    "            for ratio in ratios:\n",
    "                for (n_est, max_d, lr, subs, col) in itertools.product(\n",
    "                    xgb_params[\"n_estimators\"],\n",
    "                    xgb_params[\"max_depth\"],\n",
    "                    xgb_params[\"learning_rate\"],\n",
    "                    xgb_params[\"subsample\"],\n",
    "                    xgb_params[\"colsample_bytree\"],\n",
    "                ):\n",
    "\n",
    "                    inner_auc_values = []\n",
    "\n",
    "                    # INNER FOLD\n",
    "                    for inner_fold, (tr_idx, val_idx) in enumerate(inner.split(X_train_outer, y_train_outer), 1):\n",
    "\n",
    "                        X_tr = X_train_outer.iloc[tr_idx]\n",
    "                        y_tr = y_train_outer.iloc[tr_idx]\n",
    "                        X_val = X_train_outer.iloc[val_idx]\n",
    "                        y_val = y_train_outer.iloc[val_idx]\n",
    "\n",
    "                        # --------------------------\n",
    "                        # 샘플링 적용\n",
    "                        # --------------------------\n",
    "                        if sampling_method == \"undersample\":\n",
    "                            sampler = RandomUnderSampler(sampling_strategy=ratio, random_state=42)\n",
    "                            X_res, y_res = sampler.fit_resample(X_tr, y_tr)\n",
    "\n",
    "                        elif sampling_method == \"smote\":\n",
    "                            sampler = SMOTE(sampling_strategy=ratio, random_state=42)\n",
    "                            X_res, y_res = sampler.fit_resample(X_tr, y_tr)\n",
    "\n",
    "                        else:  # none or class_weight\n",
    "                            X_res, y_res = X_tr, y_tr\n",
    "\n",
    "                        # --------------------------\n",
    "                        # 모델 생성 (CPU)\n",
    "                        # --------------------------\n",
    "                        model = XGBClassifier(\n",
    "                            n_estimators=n_est,\n",
    "                            max_depth=max_d,\n",
    "                            learning_rate=lr,\n",
    "                            subsample=subs,\n",
    "                            colsample_bytree=col,\n",
    "                            tree_method=\"hist\",\n",
    "                            device=\"cpu\",\n",
    "                            eval_metric=\"logloss\",\n",
    "                            random_state=42,\n",
    "                        )\n",
    "\n",
    "                        # class_weight만 적용\n",
    "                        if sampling_method == \"class_weight\":\n",
    "                            model.set_params(scale_pos_weight=(len(y_res) - sum(y_res)) / sum(y_res))\n",
    "\n",
    "                        # 학습\n",
    "                        model.fit(X_res, y_res)\n",
    "\n",
    "                        # 평가\n",
    "                        val_proba = model.predict_proba(X_val)[:, 1]\n",
    "                        val_pred = (val_proba > 0.5).astype(int)\n",
    "                        auc, auprc, sen, spe, dor, lr_p, lr_m = get_metrics(y_val, val_pred, val_proba)\n",
    "\n",
    "                        inner_auc_values.append(auc)\n",
    "\n",
    "                        # 기록\n",
    "                        inner_log.append({\n",
    "                            \"outer_fold\": outer_fold,\n",
    "                            \"inner_fold\": inner_fold,\n",
    "                            \"sampling_method\": sampling_method,\n",
    "                            \"sampling_ratio\": ratio,\n",
    "                            \"n_estimators\": n_est,\n",
    "                            \"max_depth\": max_d,\n",
    "                            \"learning_rate\": lr,\n",
    "                            \"subsample\": subs,\n",
    "                            \"colsample_bytree\": col,\n",
    "                            \"AUC\": auc,\n",
    "                            \"AUPRC\" : auprc,\n",
    "                            \"sensitivity\": sen,\n",
    "                            \"specificity\": spe,\n",
    "                            \"DOR\": dor,\n",
    "                            \"LR+\": lr_p,\n",
    "                            \"LR-\": lr_m\n",
    "                        })\n",
    "\n",
    "                    # Mean AUC for this setting\n",
    "                    avg_auc_list.append({\n",
    "                        \"outer_fold\": outer_fold,\n",
    "                        \"sampling_method\": sampling_method,\n",
    "                        \"sampling_ratio\": ratio,\n",
    "                        \"n_estimators\": n_est,\n",
    "                        \"max_depth\": max_d,\n",
    "                        \"learning_rate\": lr,\n",
    "                        \"subsample\": subs,\n",
    "                        \"colsample_bytree\": col,\n",
    "                        \"mean_AUC\": np.mean(inner_auc_values),\n",
    "                    })\n",
    "\n",
    "        # ============================================================\n",
    "        # BEST MODEL SELECTED\n",
    "        # ============================================================\n",
    "        best_info = max(avg_auc_list, key=lambda x: x[\"mean_AUC\"])\n",
    "        all_best_models.append(best_info)\n",
    "\n",
    "        # ============================================================\n",
    "        # OUTER TEST ON BEST MODEL\n",
    "        # ============================================================\n",
    "        sm = best_info[\"sampling_method\"]\n",
    "        r = best_info[\"sampling_ratio\"]\n",
    "\n",
    "        # sampling 적용\n",
    "        if sm == \"undersample\":\n",
    "            sampler = RandomUnderSampler(sampling_strategy=r, random_state=42)\n",
    "            X_res, y_res = sampler.fit_resample(X_train_outer, y_train_outer)\n",
    "        elif sm == \"smote\":\n",
    "            sampler = SMOTE(sampling_strategy=r, random_state=42)\n",
    "            X_res, y_res = sampler.fit_resample(X_train_outer, y_train_outer)\n",
    "        else:\n",
    "            X_res, y_res = X_train_outer, y_train_outer\n",
    "\n",
    "        # 모델 생성\n",
    "        final_model = XGBClassifier(\n",
    "            n_estimators=best_info[\"n_estimators\"],\n",
    "            max_depth=best_info[\"max_depth\"],\n",
    "            learning_rate=best_info[\"learning_rate\"],\n",
    "            subsample=best_info[\"subsample\"],\n",
    "            colsample_bytree=best_info[\"colsample_bytree\"],\n",
    "            tree_method=\"hist\",\n",
    "            device=\"cpu\",\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        if sm == \"class_weight\":\n",
    "            final_model.set_params(scale_pos_weight=(len(y_res) - sum(y_res)) / sum(y_res))\n",
    "\n",
    "        final_model.fit(X_res, y_res)\n",
    "\n",
    "        # 테스트 평가\n",
    "        test_proba = final_model.predict_proba(X_test_outer)[:, 1]\n",
    "        test_pred = (test_proba > 0.5).astype(int)\n",
    "        auc, auprc, sen, spe, dor, lr_p, lr_m = get_metrics(y_test_outer, test_pred, test_proba)\n",
    "\n",
    "        all_outer_tests.append({\n",
    "            \"outer_fold\": outer_fold,\n",
    "            \"AUC\": auc,\n",
    "            \"AUPRC\" : auprc,\n",
    "            \"sensitivity\": sen,\n",
    "            \"specificity\": spe,\n",
    "            \"DOR\": dor,\n",
    "            \"LR+\": lr_p,\n",
    "            \"LR-\": lr_m\n",
    "        })\n",
    "\n",
    "        all_inner_logs.extend(inner_log)\n",
    "\n",
    "    # ------------------------------------\n",
    "    # RETURN STRUCTURE\n",
    "    # ------------------------------------\n",
    "    return {\n",
    "        \"inner_log\": pd.DataFrame(all_inner_logs),\n",
    "        \"best_model\": pd.DataFrame(all_best_models),\n",
    "        \"outer_test\": pd.DataFrame(all_outer_tests)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b678fe-96e9-4257-81a5-71af337af3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> XGBoost Nested CV 시작\n",
      ">>> 저장 완료:\n",
      " - /Data/taegun/prs_revision/nested_results_samplings_0117/prs_model/xgboost/chf/chf_xgb_nested_cv_all_results.csv\n",
      " - /Data/taegun/prs_revision/nested_results_samplings_0117/prs_model/xgboost/chf/chf_xgb_nested_cv_best_per_fold.csv\n",
      " - /Data/taegun/prs_revision/nested_results_samplings_0117/prs_model/xgboost/chf/chf_xgb_nested_cv_outer_test_results.csv\n",
      "\n",
      ">>> 전체 실행 시간: 1655.58초 (27.59분)\n",
      ">>> XGBoost Nested CV 시작\n",
      ">>> 저장 완료:\n",
      " - /Data/taegun/prs_revision/nested_results_samplings_0117/prs_model/xgboost/chd/chd_xgb_nested_cv_all_results.csv\n",
      " - /Data/taegun/prs_revision/nested_results_samplings_0117/prs_model/xgboost/chd/chd_xgb_nested_cv_best_per_fold.csv\n",
      " - /Data/taegun/prs_revision/nested_results_samplings_0117/prs_model/xgboost/chd/chd_xgb_nested_cv_outer_test_results.csv\n",
      "\n",
      ">>> 전체 실행 시간: 1694.68초 (28.24분)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # -----------------------------\n",
    "    # 실행 시간 시작\n",
    "    # -----------------------------\n",
    "#    disease_list = [\"dia\", \"chf\", \"chd\", \"stroke\", \"af\", \"dem\"]\n",
    "    disease_list = [\"chf\", \"chd\"]\n",
    "\n",
    "    for disease in disease_list:\n",
    "        start_time = time.time()\n",
    "\n",
    "        df = pd.read_csv(FILES[disease])\n",
    "        features = FEATURES[disease]\n",
    "        target = TARGET_NAME[disease]\n",
    "        \n",
    "        df_sub = df[features + [target]].dropna()\n",
    "        \n",
    "        X = df_sub[features]\n",
    "        y = df_sub[target]\n",
    "        \n",
    "        print(\">>> XGBoost Nested CV 시작\")\n",
    "    \n",
    "        res = run_xgb_nested_cv_cpu(\n",
    "            X=X,\n",
    "            y=y\n",
    "            # sampling_methods=sampling_methods,\n",
    "            # sampling_ratios=sampling_ratios\n",
    "        )\n",
    "    \n",
    "        df_inner = res[\"inner_log\"]\n",
    "        df_best = res[\"best_model\"]\n",
    "        df_outer = res[\"outer_test\"]\n",
    "    \n",
    "        SAVE_DIR = f\"/Data/taegun/prs_revision/nested_results_samplings_0117/prs_model/xgboost/{disease}\"\n",
    "        os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    \n",
    "        df_inner.to_csv(f\"{SAVE_DIR}/{disease}_xgb_nested_cv_all_results.csv\", index=False)\n",
    "        df_best.to_csv(f\"{SAVE_DIR}/{disease}_xgb_nested_cv_best_per_fold.csv\", index=False)\n",
    "        df_outer.to_csv(f\"{SAVE_DIR}/{disease}_xgb_nested_cv_outer_test_results.csv\", index=False)\n",
    "    \n",
    "        print(\">>> 저장 완료:\")\n",
    "        print(f\" - {SAVE_DIR}/{disease}_xgb_nested_cv_all_results.csv\")\n",
    "        print(f\" - {SAVE_DIR}/{disease}_xgb_nested_cv_best_per_fold.csv\")\n",
    "        print(f\" - {SAVE_DIR}/{disease}_xgb_nested_cv_outer_test_results.csv\")\n",
    "    \n",
    "        # -----------------------------\n",
    "        # 실행 시간 종료\n",
    "        # -----------------------------\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "    \n",
    "        print(f\"\\n>>> 전체 실행 시간: {elapsed:.2f}초 ({elapsed/60:.2f}분)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2313b4-0042-43f1-8c33-1b21ea77e01e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PRSML)",
   "language": "python",
   "name": "prsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
